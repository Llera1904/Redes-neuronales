{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perez Llera Leonardo\n",
    "## 6BM1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos paquetes\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch import optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hiper parámetros\n",
    "batchSize = 64\n",
    "epochs = 25\n",
    "learningRate = 0.001\n",
    "steps = 0\n",
    "runningLoss = 0\n",
    "printEvery = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos una transformación de los datos\n",
    "transform = transforms.Compose([transforms.Resize(32), # escalar a 32\n",
    "                                transforms.ToTensor(), # convertir a tensores\n",
    "                                transforms.Normalize([0.5], [0.5])]) # normalizar a media y desv std\n",
    "\n",
    "# Descargamos el conjunto de entrenamiento y cargamos mediante un dataLoader\n",
    "trainset = datasets.FashionMNIST('F_MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batchSize, shuffle=True)\n",
    "\n",
    "# Descargamos el conjunto de validación\n",
    "testset = datasets.FashionMNIST('F_MNIST_data/', download=True, train=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batchSize, shuffle=True)\n",
    "\n",
    "# Imprimir información estadística del conjunto de datos\n",
    "print('Train data, number of images: ', len(trainset))\n",
    "print('Test data, number of images: ', len(testset))\n",
    "\n",
    "# Nombrar las clases de acuerdo al índice que tienen\n",
    "classes = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', \n",
    "           'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "# Obtener un lote de ejemplos\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "images = images.numpy()\n",
    "\n",
    "displaySize = 10\n",
    "\n",
    "# Graficar los ejemplos junto a las clases que le corresponden\n",
    "fig = plt.figure(figsize=(25, 4))\n",
    "for idx in np.arange(displaySize):\n",
    "    ax = fig.add_subplot(2, displaySize, idx+1, xticks=[], yticks=[])\n",
    "    ax.imshow(np.squeeze(images[idx]), cmap='gray')\n",
    "    ax.set_title(classes[labels[idx]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bloque residual\n",
    "<img src=https://miro.medium.com/v2/resize:fit:786/format:webp/1*foG-iCktwwuQPfepfKyvUA.png>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convK3= lambda inChannel, outChannel, stride: nn.Conv2d(inChannel, outChannel, kernel_size=3, stride=stride, padding=1)\n",
    "\n",
    "# Implementación del residualBlock\n",
    "class residualBlock(nn.Module):\n",
    "    def __init__(self, inChannel, outChannel, stride=1, changeSize=True):\n",
    "        # Construimos la estructura del residualBlock\n",
    "        super(residualBlock, self).__init__()\n",
    "        \n",
    "        self.conv1 = convK3(inChannel, outChannel, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(outChannel)\n",
    "        self.conv2 =  convK3(outChannel, outChannel, 1)\n",
    "        self.bn2 = nn.BatchNorm2d(outChannel)\n",
    "        \n",
    "        # Cambiar tamaño\n",
    "        self.changeSize = changeSize\n",
    "        if self.changeSize:\n",
    "            self.residual = nn.Sequential(\n",
    "                nn.Conv2d(inChannel, outChannel, kernel_size=1, stride=stride),\n",
    "                nn.BatchNorm2d(outChannel)\n",
    "            )\n",
    "            \n",
    "    def forward(self, x):\n",
    "        identity = x if not self.changeSize else self.residual(x)\n",
    "        y = F.relu(self.bn1(self.conv1(x)))\n",
    "        y = self.bn2(self.conv2(y))\n",
    "        y += identity\n",
    "        \n",
    "        return F.relu(y)\n",
    "\n",
    "# Implementación de ResNet56\n",
    "class ResNet56(nn.Module):\n",
    "    def __init__(self, n=9, nClases=10):\n",
    "        # Construimos la estructura de ResNet56\n",
    "        super(ResNet56, self).__init__()\n",
    "        \n",
    "        self.conv1 = convK3(1, 16, stride=1)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.block1 = self.createBlock(n=9, inChannel=16, outChannel=16, stride=1, changeSize=False)\n",
    "        self.block2 = self.createBlock(n=9, inChannel=16, outChannel=32, stride=2)\n",
    "        self.block3 = self.createBlock(n=9, inChannel=32, outChannel=64, stride=2)\n",
    "        \n",
    "        self.fc = nn.Linear(64, nClases)\n",
    "        \n",
    "    def createBlock(selft, n, inChannel, outChannel, stride, changeSize=True):\n",
    "        block = [residualBlock(inChannel, outChannel, stride, changeSize=changeSize)]\n",
    "        for i in range(n-1):\n",
    "            block.append(residualBlock(outChannel, outChannel, stride=1, changeSize=False))\n",
    "            \n",
    "        return nn.Sequential(*block)\n",
    "        \n",
    "    \n",
    "    def forward(self, x): # Definimos el pase frontal (forward pass)\n",
    "        y = F.relu(self.bn1(self.conv1(x)))\n",
    "        y = self.block1(y)\n",
    "        y = self.block2(y)\n",
    "        y = self.block3(y)\n",
    "        y = F.adaptive_avg_pool2d(y, 1)\n",
    "        y = self.fc(y.view(y.size(0), -1))\n",
    "        \n",
    "        return F.log_softmax(y, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet56() # Instanciar la red\n",
    "model = model.to(device=device)\n",
    "criterio = loss_fn = nn.CrossEntropyLoss() # Definir la función de costo (criterio de optimización)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learningRate) # Instanciar optimizador\n",
    "# optimizer = optim.SGD(model.parameters(), lr=learningRate, momentum=0.95, weight_decay=1e-4) # Instanciar optimizador\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementamos una función de evaluación\n",
    "def validation(model, testloader, criterio):\n",
    "    testLoss = 0\n",
    "    accuracy = 0\n",
    "    for images, labels in testloader:\n",
    "        images = images.to(device=device)\n",
    "        labels = labels.to(device=device)\n",
    "    \n",
    "        output = model.forward(images)\n",
    "        testLoss += criterio(output, labels).item()\n",
    "\n",
    "        ps = torch.exp(output)\n",
    "        equality = (labels.data == ps.max(dim=1)[1])\n",
    "        accuracy += equality.type(torch.FloatTensor).mean()\n",
    "    \n",
    "    return testLoss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Antes del descenso por gradiente y el entrenamiento \n",
    "# verificaremos la exactitud que tiene sin haber sido entrenada.\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "for images, labels in testloader:\n",
    "    images = images.to(device=device)\n",
    "    labels = labels.to(device=device)\n",
    "\n",
    "    images = Variable(images)\n",
    "    \n",
    "    outputs = model.forward(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum()\n",
    "accuracy = 100 * correct.cpu().numpy() / total\n",
    "\n",
    "print(\"Porcentaje de exactitud antes de entrenar:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descenso por gradiente\n",
    "for epoch in range(epochs):\n",
    "    model.train()  # Cambiamos a modo de entrenamiento\n",
    "    for images, labels in trainloader:\n",
    "        steps += 1\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        images = images.to(device=device)\n",
    "        labels = labels.to(device=device)\n",
    "        \n",
    "        images, labels = Variable(images), Variable(labels)      \n",
    "        \n",
    "        output = model.forward(images)\n",
    "        loss = criterio(output, labels)\n",
    "        loss.backward() # Backpropagation\n",
    "        optimizer.step() # Optimización\n",
    "        \n",
    "        runningLoss += loss.item()\n",
    "        \n",
    "        if steps % printEvery == 0:\n",
    "            model.eval() # Cambiamos a modo de evaluación\n",
    "            \n",
    "            # Apagamos los gradientes, reduce memoria y cálculos\n",
    "            with torch.no_grad():\n",
    "                testLoss, accuracy = validation(model, testloader, criterio)\n",
    "                \n",
    "            print(\"Epoch: {}/{}.. \".format(epoch+1, epochs),\n",
    "                  \"Training Loss: {:.3f}.. \".format(runningLoss/printEvery),\n",
    "                  \"Test Loss: {:.3f}.. \".format(testLoss/len(testloader)),\n",
    "                  \"Test Accuracy: {:.3f}\".format(accuracy/len(testloader)))\n",
    "            \n",
    "            runningLoss = 0\n",
    "            model.train() # Regresamos a modo de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(testloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "images = images.to(device=device)\n",
    "labels = labels.to(device=device)\n",
    "    \n",
    "# get predictions\n",
    "preds = np.squeeze(model(Variable(images, volatile=True)).data.max(1, keepdim=True)[1].cpu().numpy())\n",
    "images = images.cpu().numpy()\n",
    "\n",
    "# plot the images in the batch, along with predicted and true labels\n",
    "fig = plt.figure(figsize=(25, 4))\n",
    "for idx in np.arange(displaySize):\n",
    "    ax = fig.add_subplot(2, displaySize, idx+1, xticks=[], yticks=[])\n",
    "    ax.imshow(np.squeeze(images[idx]), cmap='gray')\n",
    "    ax.set_title(\"{} ({})\".format(classes[preds[idx]], classes[labels[idx]]),\n",
    "                 color=(\"green\" if preds[idx]==labels[idx] else \"red\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
